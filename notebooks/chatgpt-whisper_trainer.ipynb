{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas torch transformers wandb tqdm scikit-learn librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from datasets import Dataset, load_metric\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Initialize WandB\n",
    "wandb.init(project=\"taglish-whisper-finetuning\")\n",
    "\n",
    "# Define training configurations\n",
    "MODEL_NAME = \"openai/whisper-small\"\n",
    "MODEL_PATH = \"/content/gdrive/Shareddrives/CS307-Thesis/Dataset/whisper_checkpoints/\"\n",
    "AUDIO_DIR = \"/content/gdrive/Shareddrives/CS307-Thesis/Dataset/single-speaker/\"\n",
    "TSV_FILE = \"/content/gdrive/Shareddrives/CS307-Thesis/Dataset/single-speaker/validated.tsv\"\n",
    "OUTPUT_DIR = \"/content/gdrive/Shareddrives/CS307-Thesis/Dataset/whisper_output/\"\n",
    "EVAL_METRICS = [\"wer\", \"cer\", \"accuracy\", \"precision\", \"recall\", \"f1\"]\n",
    "\n",
    "# Load processor and model\n",
    "processor = WhisperProcessor.from_pretrained(MODEL_NAME)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Data loading function\n",
    "def load_data(tsv_file, audio_dir, max_samples=None):\n",
    "    \"\"\"\n",
    "    Load data from TSV file with timestamp handling, compatible with both \"sec\" and \"min:sec\" formats.\n",
    "    \"\"\"\n",
    "    audio_files, transcripts, languages, timestamps = [], [], [], []\n",
    "\n",
    "    # Read TSV file\n",
    "    df = pd.read_csv(tsv_file, sep='\\t')\n",
    "    required_columns = ['path', 'start_time', 'end_time', 'language', 'sentence']\n",
    "\n",
    "    # Verify all required columns are present\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(f\"TSV file must contain columns: {required_columns}\")\n",
    "\n",
    "    # Shuffle and limit samples if specified\n",
    "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    if max_samples:\n",
    "        df = df.head(max_samples)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        audio_file = row['path']\n",
    "        if not audio_file.endswith((\".mp3\", \".wav\", \".flac\")):\n",
    "            print(f\"Skipping unsupported file type: {audio_file}\")\n",
    "            continue\n",
    "\n",
    "        full_audio_path = os.path.join(audio_dir, audio_file)\n",
    "        if not os.path.exists(full_audio_path):\n",
    "            print(f\"Warning: Audio file not found: {full_audio_path}\")\n",
    "            continue\n",
    "\n",
    "        # Parse timestamps\n",
    "        def parse_time(time_str):\n",
    "            try:\n",
    "                return float(time_str)\n",
    "            except ValueError:\n",
    "                minutes, seconds = map(float, time_str.split(\":\"))\n",
    "                return minutes * 60 + seconds\n",
    "\n",
    "        try:\n",
    "            start_time = parse_time(row['start_time'])\n",
    "            end_time = parse_time(row['end_time'])\n",
    "        except Exception as e:\n",
    "            print(f\"Error parsing timestamps for {audio_file}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        audio_files.append(full_audio_path)\n",
    "        transcripts.append(row['sentence'])\n",
    "        timestamps.append((start_time, end_time))\n",
    "        languages.append(row['language'])\n",
    "\n",
    "    return audio_files, transcripts, languages, timestamps\n",
    "\n",
    "# Load dataset\n",
    "audio_files, transcripts, languages, timestamps = load_data(TSV_FILE, AUDIO_DIR)\n",
    "\n",
    "# Data preparation for Trainer\n",
    "dataset = Dataset.from_dict({\n",
    "    \"input_values\": [processor(audio_file, sampling_rate=16000).input_values[0] for audio_file in audio_files],\n",
    "    \"labels\": transcripts\n",
    "})\n",
    "\n",
    "# Evaluation metrics\n",
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = processor.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "    accuracy = accuracy_score(label_str, pred_str)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(label_str, pred_str, average=\"weighted\")\n",
    "\n",
    "    return {\n",
    "        \"wer\": wer,\n",
    "        \"cer\": cer,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=7,\n",
    "    per_device_eval_batch_size=6,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "\n",
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    "    eval_dataset=dataset,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train and save the model\n",
    "trainer.train()\n",
    "trainer.save_model(MODEL_PATH)\n",
    "processor.save_pretrained(MODEL_PATH)\n",
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proj-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
