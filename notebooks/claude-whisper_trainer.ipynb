{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-ibBEKwExH5",
        "outputId": "d1bd2698-ddcb-4b79-f124-fd4fac96a220"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: jiwer in /usr/local/lib/python3.10/dist-packages (3.0.5)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: rapidfuzz<4,>=3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (3.10.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas torch transformers wandb tqdm scikit-learn librosa jiwer torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "VnGkKA0WExH6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from transformers import WhisperFeatureExtractor, WhisperProcessor, WhisperForConditionalGeneration\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "from jiwer import wer, cer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYnvMX7PExH7",
        "outputId": "afd808a9-6d12-41a2-fd45-5d3da8af2f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Set up Google Drive mounting\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "_sUWSpG5ExH7"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "AUDIO_DIR = '/content/gdrive/Shareddrives/CS307-Thesis/Dataset/single-speaker/'\n",
        "TSV_FILE = '/content/gdrive/Shareddrives/CS307-Thesis/Dataset/single-speaker/validated.tsv'\n",
        "CHECKPOINT_DIR = '/content/gdrive/Shareddrives/CS307-Thesis/Dataset/whisper_checkpoints/'\n",
        "MAX_SAMPLES = 13\n",
        "BATCH_SIZE = 4\n",
        "NUM_WORKERS = 2\n",
        "EPOCHS = 3\n",
        "LEARNING_RATE = 1e-5\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(tsv_file, audio_dir, max_samples=None):\n",
        "    \"\"\"\n",
        "    Load data from TSV file with timestamp handling, compatible with both \"sec\" and \"min:sec\" formats.\n",
        "    \"\"\"\n",
        "    audio_files, transcripts, languages, timestamps = [], [], [], []\n",
        "\n",
        "    # Read TSV file\n",
        "    df = pd.read_csv(tsv_file, sep='\\t')\n",
        "    required_columns = ['path', 'start_time', 'end_time', 'language', 'sentence']\n",
        "\n",
        "    # Verify all required columns are present\n",
        "    if not all(col in df.columns for col in required_columns):\n",
        "        raise ValueError(f\"TSV file must contain columns: {required_columns}\")\n",
        "\n",
        "    # Shuffle and limit samples if specified\n",
        "    df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    if max_samples:\n",
        "        df = df.head(max_samples)\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        audio_file = row['path']\n",
        "        if not audio_file.endswith((\".mp3\", \".wav\", \".flac\")):\n",
        "            print(f\"Skipping unsupported file type: {audio_file}\")\n",
        "            continue\n",
        "\n",
        "        full_audio_path = os.path.join(audio_dir, audio_file)\n",
        "        if not os.path.exists(full_audio_path):\n",
        "            print(f\"Warning: Audio file not found: {full_audio_path}\")\n",
        "            continue\n",
        "\n",
        "        # Parse timestamps\n",
        "        def parse_time(time_str):\n",
        "            try:\n",
        "                # Check if time is already in seconds\n",
        "                return float(time_str)\n",
        "            except ValueError:\n",
        "                # Convert from \"min:sec\" format to seconds\n",
        "                minutes, seconds = map(float, time_str.split(\":\"))\n",
        "                return minutes * 60 + seconds\n",
        "\n",
        "        try:\n",
        "            start_time = parse_time(row['start_time'])\n",
        "            end_time = parse_time(row['end_time'])\n",
        "        except Exception as e:\n",
        "            print(f\"Error parsing timestamps for {audio_file}: {str(e)}\")\n",
        "            continue\n",
        "\n",
        "        audio_files.append(full_audio_path)\n",
        "        transcripts.append(row['sentence'])\n",
        "        timestamps.append((start_time, end_time))\n",
        "        languages.append(row['language'])\n",
        "\n",
        "    return audio_files, transcripts, languages, timestamps"
      ],
      "metadata": {
        "id": "KDTJf8A6FNQ2"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "_5bOfrTXExH8"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "audio_files, transcripts, languages, timestamps = load_data(TSV_FILE, AUDIO_DIR, max_samples=MAX_SAMPLES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "fAdaJzSZExH8"
      },
      "outputs": [],
      "source": [
        "# Create dataset and dataloader\n",
        "class WhisperDataset(Dataset):\n",
        "    def __init__(self, audio_files, transcripts, languages, timestamps):\n",
        "        self.audio_files = audio_files\n",
        "        self.transcripts = transcripts\n",
        "        self.languages = languages\n",
        "        self.timestamps = timestamps\n",
        "        self.processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.audio_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_file = self.audio_files[idx]\n",
        "        transcript = self.transcripts[idx]\n",
        "        language = self.languages[idx]\n",
        "        start_time, end_time = self.timestamps[idx]\n",
        "\n",
        "        # Load audio\n",
        "        audio, sampling_rate = torchaudio.load(audio_file)\n",
        "\n",
        "        # Crop audio based on timestamps\n",
        "        start_frame = int(start_time * sampling_rate)\n",
        "        end_frame = int(end_time * sampling_rate)\n",
        "        audio = audio[:, start_frame:end_frame]\n",
        "\n",
        "        # Resample audio to 16kHz if necessary\n",
        "        if sampling_rate != 16000:\n",
        "            resampler = torchaudio.transforms.Resample(orig_freq=sampling_rate, new_freq=16000)\n",
        "            audio = resampler(audio)\n",
        "\n",
        "        # Pad the audio data to the expected shape\n",
        "        expected_shape = (1, audio.shape[1])\n",
        "        if audio.shape != expected_shape:\n",
        "            audio = F.pad(audio, (0, expected_shape[1] - audio.shape[1]), mode='constant', value=0)\n",
        "\n",
        "        # Preprocess audio and text\n",
        "        pixel_values = self.processor.feature_extractor(audio, sampling_rate=16000, return_tensors=\"pt\").pixel_values\n",
        "        input_ids = self.processor.tokenizer(transcript, return_tensors=\"pt\").input_ids\n",
        "\n",
        "        return {\n",
        "            \"audio\": pixel_values,\n",
        "            \"input_ids\": input_ids,\n",
        "            \"language\": language\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "dZ_wdr5ZExH9"
      },
      "outputs": [],
      "source": [
        "dataset = WhisperDataset(audio_files, transcripts, languages, timestamps)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "wP9RM5xwExH9",
        "outputId": "a32ccb75-46c7-429c-f265-242087b67f90"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing last run (ID:qsls6p96) before initializing another..."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">chocolate-pyramid-3</strong> at: <a href='https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning/runs/qsls6p96' target=\"_blank\">https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning/runs/qsls6p96</a><br/> View project at: <a href='https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning' target=\"_blank\">https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20241104_165954-qsls6p96/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Successfully finished last run (ID:qsls6p96). Initializing new run:<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.18.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241104_170149-yw3uj1ys</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning/runs/yw3uj1ys' target=\"_blank\">happy-oath-4</a></strong> to <a href='https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning' target=\"_blank\">https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning/runs/yw3uj1ys' target=\"_blank\">https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning/runs/yw3uj1ys</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/idcsalvame-n-a/whisper-fine-tuning/runs/yw3uj1ys?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b72403826b0>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Initialize Weights & Biases\n",
        "wandb.init(project=\"whisper-fine-tuning\", config={\n",
        "    \"batch_size\": BATCH_SIZE,\n",
        "    \"learning_rate\": LEARNING_RATE,\n",
        "    \"epochs\": EPOCHS,\n",
        "    \"max_samples\": MAX_SAMPLES\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tdDlzBCHExH-"
      },
      "outputs": [],
      "source": [
        "# Load Whisper model and fine-tune\n",
        "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\").to(DEVICE)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vhvV7127ExH-",
        "outputId": "f155649c-1b67-4e81-cb53-00e8b1a373a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/3:   0%|          | 0/4 [00:00<?, ?batch/s]Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7b72544f41f0><function _MultiProcessingDataLoaderIter.__del__ at 0x7b72544f41f0>\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "        if w.is_alive():self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "\n",
            "AssertionError  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            ":     can only test a child processassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "\n",
            "Traceback (most recent call last):\n",
            "\n",
            "\n",
            "AssertionError: Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7b72544f41f0>  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    Exception ignored in: self._shutdown_workers()<function _MultiProcessingDataLoaderIter.__del__ at 0x7b72544f41f0>\n",
            "\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
            "    if w.is_alive():    self._shutdown_workers()\n",
            "\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1587, in _shutdown_workers\n",
            "        assert self._parent_pid == os.getpid(), 'can only test a child process'if w.is_alive():\n",
            "\n",
            "AssertionError:   File \"/usr/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
            "    can only test a child process\n",
            "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
            "AssertionError: can only test a child process\n",
            "Epoch 1/3:   0%|          | 0/4 [00:15<?, ?batch/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-53-57badd0b684f>\", line 38, in __getitem__\n    pixel_values = self.processor.feature_extractor(audio, sampling_rate=16000, return_tensors=\"pt\").pixel_values\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/feature_extraction_whisper.py\", line 282, in __call__\n    padded_inputs = self.pad(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/feature_extraction_sequence_utils.py\", line 210, in pad\n    outputs = self._pad(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/feature_extraction_sequence_utils.py\", line 282, in _pad\n    processed_features[self.model_input_names[0]] = np.pad(\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\", line 748, in pad\n    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\", line 522, in _as_pairs\n    return np.broadcast_to(x, (ndim, 2)).tolist()\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\", line 413, in broadcast_to\n    return _broadcast_to(array, shape, subok=subok, readonly=True)\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\", line 349, in _broadcast_to\n    it = np.nditer(\nValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-23790f0e1157>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_wer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_cer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch+1}/{EPOCHS}\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0maudio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"audio\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1463\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0;31m# instantiate since we don't know how to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 715\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\", line 52, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"<ipython-input-53-57badd0b684f>\", line 38, in __getitem__\n    pixel_values = self.processor.feature_extractor(audio, sampling_rate=16000, return_tensors=\"pt\").pixel_values\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/whisper/feature_extraction_whisper.py\", line 282, in __call__\n    padded_inputs = self.pad(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/feature_extraction_sequence_utils.py\", line 210, in pad\n    outputs = self._pad(\n  File \"/usr/local/lib/python3.10/dist-packages/transformers/feature_extraction_sequence_utils.py\", line 282, in _pad\n    processed_features[self.model_input_names[0]] = np.pad(\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\", line 748, in pad\n    pad_width = _as_pairs(pad_width, array.ndim, as_index=True)\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/arraypad.py\", line 522, in _as_pairs\n    return np.broadcast_to(x, (ndim, 2)).tolist()\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\", line 413, in broadcast_to\n    return _broadcast_to(array, shape, subok=subok, readonly=True)\n  File \"/usr/local/lib/python3.10/dist-packages/numpy/lib/stride_tricks.py\", line 349, in _broadcast_to\n    it = np.nditer(\nValueError: operands could not be broadcast together with remapped shapes [original->remapped]: (2,2)  and requested shape (3,2)\n"
          ]
        }
      ],
      "source": [
        "# Load checkpoint if available\n",
        "start_epoch = 0\n",
        "if os.path.exists(os.path.join(CHECKPOINT_DIR, \"checkpoint.pt\")):\n",
        "    checkpoint = torch.load(os.path.join(CHECKPOINT_DIR, \"checkpoint.pt\"))\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "    optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "    start_epoch = checkpoint[\"epoch\"] + 1\n",
        "    print(f\"Loaded checkpoint from epoch {start_epoch}\")\n",
        "\n",
        "for epoch in range(start_epoch, EPOCHS):\n",
        "    train_loss = 0\n",
        "    train_wer, train_cer, train_acc, train_precision, train_recall, train_f1 = 0, 0, 0, 0, 0, 0\n",
        "    model.train()\n",
        "    for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", unit=\"batch\"):\n",
        "        audio = batch[\"audio\"].to(DEVICE)\n",
        "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        language = batch[\"language\"]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(audio, input_ids=input_ids, return_dict=True)\n",
        "        loss = output.loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Evaluate metrics\n",
        "        predicted_ids = output.logits.argmax(-1)\n",
        "        predicted_text = [model.processor.tokenizer.decode(p, skip_special_tokens=True) for p in predicted_ids]\n",
        "        true_text = [model.processor.tokenizer.decode(t, skip_special_tokens=True) for t in input_ids]\n",
        "        train_wer += wer(true_text, predicted_text)\n",
        "        train_cer += cer(true_text, predicted_text)\n",
        "        train_acc += (np.array(predicted_text) == np.array(true_text)).mean()\n",
        "        train_precision += (np.array(predicted_text) == np.array(true_text)).mean()\n",
        "        train_recall += (np.array(predicted_text) == np.array(true_text)).mean()\n",
        "        train_f1 += 2 * train_precision * train_recall / (train_precision + train_recall)\n",
        "\n",
        "    train_loss /= len(dataloader)\n",
        "    train_wer /= len(dataloader)\n",
        "    train_cer /= len(dataloader)\n",
        "    train_acc /= len(dataloader)\n",
        "    train_precision /= len(dataloader)\n",
        "    train_recall /= len(dataloader)\n",
        "    train_f1 /= len(dataloader)\n",
        "\n",
        "    # Log metrics to Weights & Biases\n",
        "    wandb.log({\n",
        "        \"train_loss\": train_loss,\n",
        "        \"train_wer\": train_wer,\n",
        "        \"train_cer\": train_cer,\n",
        "        \"train_accuracy\": train_acc,\n",
        "        \"train_precision\": train_precision,\n",
        "        \"train_recall\": train_recall,\n",
        "        \"train_f1\": train_f1\n",
        "    })\n",
        "\n",
        "    # Save checkpoint\n",
        "    checkpoint = {\n",
        "        \"epoch\": epoch,\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"optimizer_state_dict\": optimizer.state_dict()\n",
        "    }\n",
        "    torch.save(checkpoint, os.path.join(CHECKPOINT_DIR, \"checkpoint.pt\"))\n",
        "    print(f\"Checkpoint saved for epoch {epoch+1}\")\n",
        "\n",
        "print(\"Training complete!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "proj-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}